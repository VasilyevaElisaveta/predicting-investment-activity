{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-16 12:14:18,328] A new study created in memory with name: no-name-2bc3ab94-cceb-4b4a-925f-daf465e924ce\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ee18b739094773a070e2126c494cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-16 12:14:51,515] Trial 0 finished with value: 0.384048193693161 and parameters: {'n_filters': 128, 'kernel_size': 3, 'n_blocks': 5, 'dropout': 0.11315371344546471, 'lr': 2.143421753597418e-05, 'weight_decay': 7.657322158011464e-05, 'batch_size': 64, 'mlp_hidden': 64, 'epochs': 68}. Best is trial 0 with value: 0.384048193693161.\n",
      "[I 2025-12-16 12:15:22,277] Trial 1 finished with value: 0.40717798471450806 and parameters: {'n_filters': 32, 'kernel_size': 3, 'n_blocks': 5, 'dropout': 0.1502584708052767, 'lr': 0.0006843480966779932, 'weight_decay': 6.10389237511571e-07, 'batch_size': 64, 'mlp_hidden': 256, 'epochs': 77}. Best is trial 0 with value: 0.384048193693161.\n",
      "[I 2025-12-16 12:15:27,442] Trial 2 finished with value: 0.732684850692749 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 5, 'dropout': 0.4429983770186373, 'lr': 0.00010635935925478696, 'weight_decay': 5.644978252707073e-08, 'batch_size': 32, 'mlp_hidden': 256, 'epochs': 5}. Best is trial 0 with value: 0.384048193693161.\n",
      "[I 2025-12-16 12:15:45,479] Trial 3 finished with value: 0.36101028323173523 and parameters: {'n_filters': 128, 'kernel_size': 3, 'n_blocks': 2, 'dropout': 0.06458780361083488, 'lr': 1.840367518087737e-05, 'weight_decay': 2.9390415719009105e-05, 'batch_size': 64, 'mlp_hidden': 64, 'epochs': 74}. Best is trial 3 with value: 0.36101028323173523.\n",
      "[I 2025-12-16 12:15:50,673] Trial 4 finished with value: 0.2778909206390381 and parameters: {'n_filters': 16, 'kernel_size': 3, 'n_blocks': 3, 'dropout': 0.0608197919586409, 'lr': 0.0017292151485049803, 'weight_decay': 2.122809172569212e-05, 'batch_size': 32, 'mlp_hidden': 256, 'epochs': 11}. Best is trial 4 with value: 0.2778909206390381.\n",
      "[I 2025-12-16 12:15:51,194] Trial 5 pruned. \n",
      "[I 2025-12-16 12:16:29,101] Trial 6 pruned. \n",
      "[I 2025-12-16 12:16:55,616] Trial 7 finished with value: 0.28012171387672424 and parameters: {'n_filters': 32, 'kernel_size': 7, 'n_blocks': 2, 'dropout': 0.42782449661935923, 'lr': 0.000872179635219099, 'weight_decay': 7.553862010656362e-06, 'batch_size': 16, 'mlp_hidden': 256, 'epochs': 38}. Best is trial 4 with value: 0.2778909206390381.\n",
      "[I 2025-12-16 12:17:51,205] Trial 8 finished with value: 0.4355393350124359 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 5, 'dropout': 0.11331410878728349, 'lr': 0.0020345305294280267, 'weight_decay': 1.9278401490868392e-08, 'batch_size': 16, 'mlp_hidden': 128, 'epochs': 32}. Best is trial 4 with value: 0.2778909206390381.\n",
      "[I 2025-12-16 12:18:59,174] Trial 9 pruned. \n",
      "[I 2025-12-16 12:19:23,881] Trial 10 finished with value: 0.4825887084007263 and parameters: {'n_filters': 16, 'kernel_size': 3, 'n_blocks': 3, 'dropout': 0.0024618950474314394, 'lr': 0.008492848230034933, 'weight_decay': 0.000759569362838274, 'batch_size': 32, 'mlp_hidden': 32, 'epochs': 49}. Best is trial 4 with value: 0.2778909206390381.\n",
      "[I 2025-12-16 12:19:53,924] Trial 11 finished with value: 0.3491310179233551 and parameters: {'n_filters': 32, 'kernel_size': 7, 'n_blocks': 3, 'dropout': 0.2971609280610319, 'lr': 0.0017658793304703266, 'weight_decay': 9.590805330922467e-05, 'batch_size': 16, 'mlp_hidden': 256, 'epochs': 29}. Best is trial 4 with value: 0.2778909206390381.\n",
      "[I 2025-12-16 12:19:54,708] Trial 12 pruned. \n",
      "[I 2025-12-16 12:19:57,102] Trial 13 pruned. \n",
      "[I 2025-12-16 12:20:00,690] Trial 14 pruned. \n",
      "[I 2025-12-16 12:20:01,130] Trial 15 pruned. \n",
      "[I 2025-12-16 12:20:07,803] Trial 16 finished with value: 0.5093836784362793 and parameters: {'n_filters': 16, 'kernel_size': 7, 'n_blocks': 3, 'dropout': 0.24009615346595353, 'lr': 0.003243484842750256, 'weight_decay': 1.8020751484705633e-07, 'batch_size': 16, 'mlp_hidden': 256, 'epochs': 7}. Best is trial 4 with value: 0.2778909206390381.\n",
      "[I 2025-12-16 12:20:10,205] Trial 17 pruned. \n",
      "[I 2025-12-16 12:20:35,093] Trial 18 finished with value: 0.21502505242824554 and parameters: {'n_filters': 32, 'kernel_size': 3, 'n_blocks': 2, 'dropout': 0.03808459243236044, 'lr': 0.004853422403992681, 'weight_decay': 3.739315217054428e-06, 'batch_size': 32, 'mlp_hidden': 128, 'epochs': 58}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:21:02,619] Trial 19 finished with value: 0.5072916150093079 and parameters: {'n_filters': 16, 'kernel_size': 3, 'n_blocks': 3, 'dropout': 0.008582623640667107, 'lr': 0.005666572986710236, 'weight_decay': 3.002639305123139e-06, 'batch_size': 32, 'mlp_hidden': 128, 'epochs': 57}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:21:28,425] Trial 20 finished with value: 0.608756422996521 and parameters: {'n_filters': 64, 'kernel_size': 3, 'n_blocks': 2, 'dropout': 0.05558075755906279, 'lr': 0.004455682118758004, 'weight_decay': 2.058291513554404e-05, 'batch_size': 32, 'mlp_hidden': 128, 'epochs': 67}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:21:28,850] Trial 21 pruned. \n",
      "[I 2025-12-16 12:21:29,261] Trial 22 pruned. \n",
      "[I 2025-12-16 12:21:29,576] Trial 23 pruned. \n",
      "[I 2025-12-16 12:21:30,011] Trial 24 pruned. \n",
      "[I 2025-12-16 12:21:45,255] Trial 25 finished with value: 0.30378958582878113 and parameters: {'n_filters': 16, 'kernel_size': 7, 'n_blocks': 3, 'dropout': 0.06769209541524387, 'lr': 0.0011176684536038262, 'weight_decay': 0.00026495522823848886, 'batch_size': 16, 'mlp_hidden': 128, 'epochs': 18}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:21:46,050] Trial 26 pruned. \n",
      "[I 2025-12-16 12:21:46,689] Trial 27 pruned. \n",
      "[I 2025-12-16 12:21:46,981] Trial 28 pruned. \n",
      "[I 2025-12-16 12:21:47,699] Trial 29 pruned. \n",
      "[I 2025-12-16 12:21:47,950] Trial 30 pruned. \n",
      "[I 2025-12-16 12:21:50,551] Trial 31 pruned. \n",
      "[I 2025-12-16 12:21:51,436] Trial 32 pruned. \n",
      "[I 2025-12-16 12:21:52,322] Trial 33 pruned. \n",
      "[I 2025-12-16 12:21:54,394] Trial 34 pruned. \n",
      "[I 2025-12-16 12:21:54,625] Trial 35 pruned. \n",
      "[I 2025-12-16 12:21:55,139] Trial 36 pruned. \n",
      "[I 2025-12-16 12:22:22,496] Trial 37 finished with value: 0.3345436453819275 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 2, 'dropout': 0.1413714892360452, 'lr': 0.004055622182866843, 'weight_decay': 0.00015555209137748792, 'batch_size': 16, 'mlp_hidden': 256, 'epochs': 32}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:22:23,027] Trial 38 pruned. \n",
      "[I 2025-12-16 12:22:26,246] Trial 39 pruned. \n",
      "[I 2025-12-16 12:22:26,886] Trial 40 pruned. \n",
      "[I 2025-12-16 12:22:55,072] Trial 41 pruned. \n",
      "[I 2025-12-16 12:22:56,818] Trial 42 pruned. \n",
      "[I 2025-12-16 12:23:01,206] Trial 43 pruned. \n",
      "[I 2025-12-16 12:23:29,016] Trial 44 finished with value: 0.32382869720458984 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 3, 'dropout': 0.07198257177946076, 'lr': 0.0021864380119953515, 'weight_decay': 0.0009869346398672285, 'batch_size': 16, 'mlp_hidden': 256, 'epochs': 24}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:23:37,151] Trial 45 pruned. \n",
      "[I 2025-12-16 12:23:38,978] Trial 46 pruned. \n",
      "[I 2025-12-16 12:23:39,273] Trial 47 pruned. \n",
      "[I 2025-12-16 12:23:41,381] Trial 48 pruned. \n",
      "[I 2025-12-16 12:23:42,305] Trial 49 pruned. \n",
      "[I 2025-12-16 12:23:42,911] Trial 50 pruned. \n",
      "[I 2025-12-16 12:23:45,518] Trial 51 pruned. \n",
      "[I 2025-12-16 12:23:51,583] Trial 52 pruned. \n",
      "[I 2025-12-16 12:24:22,865] Trial 53 finished with value: 0.3737280070781708 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 3, 'dropout': 0.07337031098664831, 'lr': 0.0016169298854221664, 'weight_decay': 2.0531388789862562e-05, 'batch_size': 16, 'mlp_hidden': 256, 'epochs': 27}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:24:26,417] Trial 54 pruned. \n",
      "[I 2025-12-16 12:24:27,151] Trial 55 pruned. \n",
      "[I 2025-12-16 12:24:27,878] Trial 56 pruned. \n",
      "[I 2025-12-16 12:24:28,421] Trial 57 pruned. \n",
      "[I 2025-12-16 12:24:29,333] Trial 58 pruned. \n",
      "[I 2025-12-16 12:24:29,709] Trial 59 pruned. \n",
      "[I 2025-12-16 12:24:31,507] Trial 60 pruned. \n",
      "[I 2025-12-16 12:24:32,432] Trial 61 pruned. \n",
      "[I 2025-12-16 12:24:33,346] Trial 62 pruned. \n",
      "[I 2025-12-16 12:24:34,471] Trial 63 pruned. \n",
      "[I 2025-12-16 12:24:35,374] Trial 64 pruned. \n",
      "[I 2025-12-16 12:24:35,671] Trial 65 pruned. \n",
      "[I 2025-12-16 12:24:36,058] Trial 66 pruned. \n",
      "[I 2025-12-16 12:24:36,994] Trial 67 pruned. \n",
      "[I 2025-12-16 12:24:37,385] Trial 68 pruned. \n",
      "[I 2025-12-16 12:24:38,664] Trial 69 pruned. \n",
      "[I 2025-12-16 12:24:39,062] Trial 70 pruned. \n",
      "[I 2025-12-16 12:24:39,337] Trial 71 pruned. \n",
      "[I 2025-12-16 12:24:39,602] Trial 72 pruned. \n",
      "[I 2025-12-16 12:24:39,870] Trial 73 pruned. \n",
      "[I 2025-12-16 12:24:40,106] Trial 74 pruned. \n",
      "[I 2025-12-16 12:24:40,485] Trial 75 pruned. \n",
      "[I 2025-12-16 12:24:41,428] Trial 76 pruned. \n",
      "[I 2025-12-16 12:24:46,077] Trial 77 pruned. \n",
      "[I 2025-12-16 12:25:36,365] Trial 78 finished with value: 0.3002581298351288 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 2, 'dropout': 0.023051774891708267, 'lr': 0.0013704025223833767, 'weight_decay': 0.00013884845639452906, 'batch_size': 32, 'mlp_hidden': 64, 'epochs': 100}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:25:36,942] Trial 79 pruned. \n",
      "[I 2025-12-16 12:25:37,507] Trial 80 pruned. \n",
      "[I 2025-12-16 12:26:17,399] Trial 81 finished with value: 0.3972007930278778 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 2, 'dropout': 0.017098171492195866, 'lr': 0.0021653782451217336, 'weight_decay': 8.524043312457602e-05, 'batch_size': 32, 'mlp_hidden': 64, 'epochs': 78}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:26:51,499] Trial 82 finished with value: 0.35125869512557983 and parameters: {'n_filters': 128, 'kernel_size': 7, 'n_blocks': 2, 'dropout': 0.04350734487721246, 'lr': 0.0017421256283892156, 'weight_decay': 0.000351883321703124, 'batch_size': 32, 'mlp_hidden': 64, 'epochs': 67}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:26:52,070] Trial 83 pruned. \n",
      "[I 2025-12-16 12:26:53,144] Trial 84 pruned. \n",
      "[I 2025-12-16 12:26:54,249] Trial 85 pruned. \n",
      "[I 2025-12-16 12:26:54,655] Trial 86 pruned. \n",
      "[I 2025-12-16 12:26:55,224] Trial 87 pruned. \n",
      "[I 2025-12-16 12:26:55,780] Trial 88 pruned. \n",
      "[I 2025-12-16 12:26:56,858] Trial 89 pruned. \n",
      "[I 2025-12-16 12:27:14,851] Trial 90 finished with value: 0.5631421208381653 and parameters: {'n_filters': 32, 'kernel_size': 7, 'n_blocks': 3, 'dropout': 0.05879468073912726, 'lr': 0.0026425910729855405, 'weight_decay': 7.065142074996737e-06, 'batch_size': 32, 'mlp_hidden': 256, 'epochs': 33}. Best is trial 18 with value: 0.21502505242824554.\n",
      "[I 2025-12-16 12:27:16,651] Trial 91 pruned. \n",
      "[I 2025-12-16 12:27:22,633] Trial 92 pruned. \n",
      "[I 2025-12-16 12:27:22,920] Trial 93 pruned. \n",
      "[I 2025-12-16 12:27:23,317] Trial 94 pruned. \n",
      "[I 2025-12-16 12:27:26,011] Trial 95 pruned. \n",
      "[I 2025-12-16 12:27:34,438] Trial 96 pruned. \n",
      "[I 2025-12-16 12:27:35,552] Trial 97 pruned. \n",
      "[I 2025-12-16 12:27:36,488] Trial 98 pruned. \n",
      "[I 2025-12-16 12:27:36,936] Trial 99 pruned. \n",
      "Лучшие параметры: {'n_filters': 32, 'kernel_size': 3, 'n_blocks': 2, 'dropout': 0.03808459243236044, 'lr': 0.004853422403992681, 'weight_decay': 3.739315217054428e-06, 'batch_size': 32, 'mlp_hidden': 128, 'epochs': 58}\n",
      "\n",
      "Метрики 2023:\n",
      "MAE_log: 0.21502505242824554\n",
      "MSE_log: 0.0737835243344307\n",
      "R2_log: 0.9453837871551514\n",
      "MAE_real: 121290.96875\n",
      "MSE_real: 204558155776.0\n",
      "RMSE_real: 452281.05838737043\n",
      "MAPE_real: 0.23931945860385895\n",
      "SMAPE_real: 21.243806183338165\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "import re\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_PATH = \"dataset_vrp/2014-2023_lags_EWM_targets_train.xlsx\"\n",
    "TARGET_LOG_COL = \"log_target_next_year\"\n",
    "TEST_YEAR = 2023\n",
    "TRAIN_MAX_YEAR = 2022\n",
    "N_TRIALS = 100\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if not np.any(mask): \n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    denom = np.abs(y_true) + np.abs(y_pred)\n",
    "    mask = denom != 0\n",
    "    if not np.any(mask): \n",
    "        return np.nan\n",
    "    return 100 * np.mean(2 * np.abs(y_pred[mask] - y_true[mask]) / denom[mask])\n",
    "\n",
    "def compute_all_metrics(y_log_true, y_log_pred):\n",
    "    mae_log = mean_absolute_error(y_log_true, y_log_pred)\n",
    "    mse_log = mean_squared_error(y_log_true, y_log_pred)\n",
    "    r2_log = r2_score(y_log_true, y_log_pred)\n",
    "    y_real_true = np.exp(y_log_true)\n",
    "    y_real_pred = np.exp(y_log_pred)\n",
    "    mae_real = mean_absolute_error(y_real_true, y_real_pred)\n",
    "    mse_real = mean_squared_error(y_real_true, y_real_pred)\n",
    "    rmse_real = math.sqrt(mse_real)\n",
    "    mape_real = mape(y_real_true, y_real_pred)\n",
    "    smape_real = smape(y_real_true, y_real_pred)\n",
    "    return {\n",
    "        \"MAE_log\": mae_log,\n",
    "        \"MSE_log\": mse_log,\n",
    "        \"R2_log\": r2_log,\n",
    "        \"MAE_real\": mae_real,\n",
    "        \"MSE_real\": mse_real,\n",
    "        \"RMSE_real\": rmse_real,\n",
    "        \"MAPE_real\": mape_real,\n",
    "        \"SMAPE_real\": smape_real\n",
    "    }\n",
    "\n",
    "\n",
    "def infer_lag_groups(columns: List[str]) -> Tuple[Dict[str, List[str]], List[str]]:\n",
    "    lag_pattern = re.compile(r\"^(.*)_lag_(\\d+)$\")\n",
    "    groups, others = {}, []\n",
    "    for c in columns:\n",
    "        m = lag_pattern.match(c)\n",
    "        if m:\n",
    "            base, idx = m.group(1), int(m.group(2))\n",
    "            groups.setdefault(base, []).append((idx, c))\n",
    "        else:\n",
    "            others.append(c)\n",
    "    groups_ordered = {base: [col for _, col in sorted(lst)] for base, lst in groups.items()}\n",
    "\n",
    "    return groups_ordered, others\n",
    "\n",
    "\n",
    "class VRPDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, seq_groups: Dict[str, List[str]], static_cols: List[str],\n",
    "                 seq_scalers: Dict[str, StandardScaler] = None, static_scaler: StandardScaler = None, is_train=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.seq_groups = seq_groups\n",
    "        self.static_cols = static_cols\n",
    "        self.seq_names = list(seq_groups.keys())\n",
    "        self.seq_len = len(seq_groups[self.seq_names[0]]) if self.seq_names else 0\n",
    "\n",
    "        seq_arrays = [df[seq_groups[base]].values.astype(np.float32) for base in self.seq_names]\n",
    "        self.seq = np.stack(seq_arrays, axis=1) if seq_arrays else np.zeros((len(df),0,0), np.float32)\n",
    "        self.static = df[static_cols].values.astype(np.float32) if static_cols else np.zeros((len(df),0), np.float32)\n",
    "        self.y_log = df[TARGET_LOG_COL].values.astype(np.float32)\n",
    "\n",
    "        self.seq_scalers = seq_scalers or {}\n",
    "        if is_train:\n",
    "            for i, base in enumerate(self.seq_names):\n",
    "                sc = StandardScaler()\n",
    "                sc.fit(self.seq[:, i, :])\n",
    "                self.seq_scalers[base] = sc\n",
    "        if static_scaler is None and is_train and self.static.shape[1]>0:\n",
    "            static_scaler = StandardScaler().fit(self.static)\n",
    "        self.static_scaler = static_scaler\n",
    "\n",
    "        for i, base in enumerate(self.seq_names):\n",
    "            sc = self.seq_scalers.get(base)\n",
    "            if sc: \n",
    "                self.seq[:, i, :] = sc.transform(self.seq[:, i, :])\n",
    "        if self.static_scaler and self.static.shape[1] > 0:\n",
    "            self.static = self.static_scaler.transform(self.static)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.seq[idx]).float(), torch.from_numpy(self.static[idx]).float(), torch.tensor(self.y_log[idx]).float()\n",
    "\n",
    "\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, dropout, stride=1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size,\n",
    "                               stride=stride, padding=padding, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size,\n",
    "                               padding=padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class ResNet1D_Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_channels,\n",
    "        seq_len,\n",
    "        n_filters=64,\n",
    "        kernel_size=3,\n",
    "        n_blocks=2,\n",
    "        dropout=0.1,\n",
    "        static_size=0,\n",
    "        mlp_hidden=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_channels = seq_channels\n",
    "\n",
    "        if seq_channels > 0:\n",
    "            self.stem = nn.Sequential(\n",
    "                nn.Conv1d(seq_channels, n_filters, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(n_filters),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.stem = None\n",
    "\n",
    "        self.stage1 = self._make_stage(\n",
    "            n_filters, n_filters, n_blocks, kernel_size, dropout, stride=1\n",
    "        )\n",
    "        self.stage2 = self._make_stage(\n",
    "            n_filters, n_filters * 2, n_blocks, kernel_size, dropout, stride=2\n",
    "        )\n",
    "        self.stage3 = self._make_stage(\n",
    "            n_filters * 2, n_filters * 4, n_blocks, kernel_size, dropout, stride=2\n",
    "        )\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        mlp_in = (n_filters * 4 if seq_channels > 0 else 0) + static_size\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_in, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden // 2, 1)\n",
    "        )\n",
    "\n",
    "    def _make_stage(self, in_ch, out_ch, n_blocks, kernel_size, dropout, stride):\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            ResBlock1D(in_ch, out_ch, kernel_size, dropout, stride=stride)\n",
    "        )\n",
    "        for _ in range(1, n_blocks):\n",
    "            layers.append(\n",
    "                ResBlock1D(out_ch, out_ch, kernel_size, dropout, stride=1)\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, seq, static):\n",
    "        if self.seq_channels > 0:\n",
    "            x = self.stem(seq)\n",
    "            x = self.stage1(x)\n",
    "            x = self.stage2(x)\n",
    "            x = self.stage3(x)\n",
    "            x = self.global_pool(x).squeeze(-1)\n",
    "        else:\n",
    "            x = torch.zeros((seq.shape[0], 0), device=seq.device)\n",
    "\n",
    "        if static.numel() > 0:\n",
    "            x = torch.cat([x, static], dim=1)\n",
    "\n",
    "        return self.mlp(x).squeeze(-1)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for seq, static, y in loader:\n",
    "        seq, static, y = seq.to(DEVICE), static.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(seq, static), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item() * seq.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "def eval_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total, ys, preds = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for seq, static, y in loader:\n",
    "            seq, static, y = seq.to(DEVICE), static.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(seq, static)\n",
    "            total += criterion(pred, y).item()*seq.size(0)\n",
    "            ys.append(y.cpu().numpy())\n",
    "            preds.append(pred.cpu().numpy())\n",
    "    ys = np.concatenate(ys)\n",
    "    preds = np.concatenate(preds)\n",
    "    return total/len(loader.dataset), ys, preds\n",
    "\n",
    "\n",
    "def objective(trial, df):\n",
    "    n_filters = trial.suggest_categorical(\"n_filters\", [16, 32, 64, 128])\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5, 7])\n",
    "    n_blocks = trial.suggest_int(\"n_blocks\", 2, 5)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-8, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    mlp_hidden = trial.suggest_categorical(\"mlp_hidden\", [32, 64, 128, 256])\n",
    "    epochs = trial.suggest_int(\"epochs\", 5, 100)\n",
    "\n",
    "    df_train = df[df.year<=TRAIN_MAX_YEAR].reset_index(drop=True)\n",
    "    df_test = df[df.year==TEST_YEAR].reset_index(drop=True)\n",
    "    if len(df_train) < 10: \n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    seq_groups, others = infer_lag_groups(df.columns.tolist())\n",
    "    id_like = {\"district\", \"region\", \"year\", \"region_encoded\", \"okrug_encoded\"}\n",
    "    target_cols = {TARGET_LOG_COL, \"target_next_year\", \"delta_target\", \"delta_target_percent\"}\n",
    "    static_cols = [c for c in others if c not in id_like and c not in target_cols and \"_lag_\" not in c]\n",
    "\n",
    "    seq_scalers = {base: StandardScaler().fit(df_train[cols].values.astype(np.float32)) for base,cols in seq_groups.items()}\n",
    "    static_scaler = StandardScaler().fit(df_train[static_cols].values.astype(np.float32)) if static_cols else None\n",
    "\n",
    "    train_ds = VRPDataset(df_train,seq_groups,static_cols,seq_scalers,static_scaler)\n",
    "    test_ds = VRPDataset(df_test,seq_groups,static_cols,seq_scalers,static_scaler)\n",
    "\n",
    "    train_loader = DataLoader(train_ds,batch_size=batch_size,shuffle=True)\n",
    "    test_loader = DataLoader(test_ds,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    model = ResNet1D_Model(len(seq_groups), train_ds.seq_len, n_filters, kernel_size, n_blocks, dropout, train_ds.static.shape[1], mlp_hidden).to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_state = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        train_loss, _, _ = eval_model(model, train_loader, criterion)\n",
    "        trial.report(train_loss, epoch)\n",
    "        if trial.should_prune(): \n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    _, y_test, y_pred_log = eval_model(model, test_loader, criterion)\n",
    "    metrics = compute_all_metrics(y_test, y_pred_log)\n",
    "    trial.set_user_attr(\"metrics\", metrics)\n",
    "    return metrics[\"MAE_log\"]\n",
    "\n",
    "\n",
    "def run_hpo(n_trials=N_TRIALS, data_path=DATA_PATH):\n",
    "    df = pd.read_excel(data_path)\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda t: objective(t, df), n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    trial = study.best_trial\n",
    "    print(f\"Лучшие параметры: {trial.params}\")\n",
    "    print(f\"\\nМетрики 2023:\")\n",
    "    for name, value in trial.user_attrs.get(\"metrics\", {}).items():\n",
    "        print(f\"{name}: {value}\")\n",
    "    return study\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    run_hpo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465736ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
